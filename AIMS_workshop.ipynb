{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ba11f0",
   "metadata": {},
   "source": [
    "# CSIR-IBM Quantum Innovation Center Hands-On Workshop\n",
    "## Quantum Machine Learning Practical Session with Qiskit\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0. [Introduction to the QML Practical Session with Qiskit!](#welcome)<br>\n",
    "0.1. [Install Qiskit](#install)<br>\n",
    "0.2. [Import Modules and Download IRIS Dataset](#import)<br>\n",
    "0.3. [Overview of the QML Pipeline Adapted from Qiskit Patterns](#introduction)<br>\n",
    "2. [Loading the Classical Iris Dataset onto A Quantum Circuit](#cml)<br>\n",
    "A. [Data Analysis and Feature Extraction](#data_analysis)<br>\n",
    "B. [Splitting Data](#data_split)<br>\n",
    "C. [Data Encoding Using the ZFM](#data_encoding)\n",
    "3. [Preparing Classical Data for a Quantum Circuit](#prep)<br>\n",
    "4. [Optimise the Problem for Quantum Execution](#optimise)<br>\n",
    "5. [Execute Using Qiskit Primitives](#execute)<br>\n",
    "6. [Post-Process Results to Extract Classical Data](#post)<br>\n",
    "7. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179bd42",
   "metadata": {},
   "source": [
    "### 0. Introduction to the QML Practical Session with Qiskit! <a id=\"welcome\"></a>\n",
    "Welcome to the Quantum Machine Learning (QML) Hands-on Workshop curated for the CSIR-IBM Quantum Innovation Center! The main goal of this session is to demonstrate how IBM Research scientists and engineers leverage Qiskit Patterns to execute QML workflows. In particular, we demonstrate an implementation of Variational Quantum Classifiers (VQCs) in labeling unseen images from the well-known IRIS dataset containing three iris species: Setosa, Versicolour, and Virginica.\n",
    "\n",
    "QML can be described as a quantum computing paradigm that applies quantum mechanical phenomena such as superposition and entanglement to enable researchers to extract insights and patterns from data.â€‹ At IBM Research, we exploit QML across multiple industry such healthcare, finance, and chemistry, to augment or complement existing classical workflows.\n",
    "\n",
    "Before we begin, it is prudent to note that quantum computing paradigms can have provable adantage over classical computing for specific problems, pending progress in areas concerned with the stability of qubits and quantum systems. Despite the bottleneck in quantum hardware, we can demonstrate that by fine tuning parameters in the quantum algorithm using the Qiskit SDK which follows Qiskit Patterns, we can leverage the high performance of quantum computers to build efficient QML worklfows. \n",
    "\n",
    "The Qiskit SDK is a fundamental toolkit for performing quantum experiments. We begin verifying that Qiskit 2.x is installed and setup the required modules for visualising data. Then, we ensure that the IRIS dataset is stored in our local environment.\n",
    "#### 0.1. Install Qiskit <a id=\"install\"></a>\n",
    "\n",
    "In the below cells, we install Qiskit using $\\texttt{pip}$ and check the Qiskit version. The minimum version required to run workloads on the new IBM Quantum Platform released in July 2025 is 2.0.0. Then, we perform QML on classical data as inputs that are encoded to quantum information. Typically, data encoding is the first step in the QML pipeline. The full methodology follows the Qiskit Pattern framework as illustrated in the figure 0.1 below:\n",
    "1. Mapping classical inputs to a quantum problem.\n",
    "2. Optimising the problem for execution on available quantum systems.\n",
    "3. Executing quantum circuits on hardware using the Qiskit Runtime primitives.\n",
    "4. Post-processing, returning the result in classical format.\n",
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"images/qiskit_patterns.png\" />\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "    Figure 0.1. illustrating the full framework for classifying iris species using a QNN. \n",
    "</p>\n",
    "To investigate QML further, we encourage you to visit the  <a href=https://quantum.cloud.ibm.com/learning/en/courses/quantum-machine-learning/introduction> Quantum Machine Learning course material</a> by IBM Quantum. For now, let's verify that we have Qiskit installed on our devices. If you do not have Qiskit on your machine, you can uncomment the cell below to install it, among other modules that we will be using moving forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install qiskit qiskit-machine-learning seaborn scikit-learn pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d61779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "print(f\"Qiskit version: {qiskit.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f0a3d",
   "metadata": {},
   "source": [
    "#### 0.2. Import Modules <a id=\"import\"></a>\n",
    "\n",
    "Qiskit is an open source project created by IBM to enable quantum researchers to programmatically interface to IBM Quantum hardware. Over the years, Qiskit has evolved to include powerful modules to expedite the development of quantum algorithms. Among these is the $\\texttt{transpiler}$ package, which interprets quantum circuits and optimizes the conversion of logical qubits to specific qubits on our hardware. Because our QML pipeline implementats a classical-quantum hybrid stream, we can also leverage common Python modules to optimize certain parts of our workflow. \n",
    "\n",
    "To run workflows on IBM Quantum hardware, researchers at IBM Research us Qiskit Runtime, which is the architecture that streamlines computations requiring multiple iterations. Qiskit Runtime enables algorithms to execute significantly faster. \n",
    "\n",
    "For the purpose of this demonstration, we will use the Estimator, which is a Qiskit Runtime primitive that simulates the execution of the quantum part of our QML pipeline on hardware. For more information, on the packages used, visit the <a href='https://quantum.cloud.ibm.com/docs/en/api/qiskit-ibm-runtime/runtime-service'>documentation on the IBM Quantum Platform</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit.circuit.library import ZFeatureMap, z_feature_map, RealAmplitudes, TwoLocal\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import BaseEstimatorV2\n",
    "from qiskit.quantum_info.operators.base_operator import BaseOperator\n",
    "from scipy.optimize import minimize\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit.circuit.library import XGate\n",
    "from qiskit.transpiler import PassManager\n",
    "from qiskit.transpiler.passes import (\n",
    "    ALAPScheduleAnalysis,\n",
    "    ConstrainedReschedule,\n",
    "    PadDynamicalDecoupling,\n",
    ")\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from qiskit.primitives import StatevectorEstimator as Estimator  # simulator\n",
    "from qiskit_ibm_runtime import (\n",
    "    EstimatorV2 as Estimator2,\n",
    "    Session,\n",
    ")\n",
    "from qiskit_machine_learning.utils import algorithm_globals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b5104",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Account Set Up: API Key and CRN</b>\n",
    "\n",
    "- Enter your API Key and CRN.\n",
    "\n",
    "**Your Goal:** Please enter your IBM Quantum Platform API Key and CRN in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f61184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- TODO : Setup an Instance---\n",
    "# Enter your own API key and CRN from the IBM Quantum Platform\n",
    "\n",
    "your_api_key = \"REPLACE_WITH_YOUR_API_KEY\"\n",
    "your_crn = \"REPLACE_WITH_YOUR_CRN\"\n",
    "\n",
    "# Construct account object for interacting with Qiskit Runtime service\n",
    "QiskitRuntimeService.save_account(\n",
    "    channel=\"ibm_quantum_platform\",\n",
    "    token=your_api_key,\n",
    "    instance=your_crn,\n",
    "    name=\"qml4africa\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "service = QiskitRuntimeService(name=\"qml4africa\")\n",
    "service.saved_accounts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a7d9b",
   "metadata": {},
   "source": [
    "#### 0.3. Overview of the QML Pipeline Adapted from Qiskit Patterns<a id=\"introduction\"></a>\n",
    "\n",
    "In this practical, we will follow an adapted version of the Qiskit Pattern to perform supervised classification by:\n",
    "1. Loading the classical $\\texttt{iris\\_dataset}$ and encoding it to quantum information.\n",
    "2. Generate and adjust the variational quantum circuit (VQC) and ansatz circuit for our quantum neural network (QNN).\n",
    "3. Use Qiskit Primitives on the trained QNN to predict the iris species.\n",
    "4. Explore ways to scale the classification problem.\n",
    "\n",
    "Subroutines involved in each step are included in figure 0.2., illustrating the full QML pipeline for classifying irises into three groups. For each task, we will begin with a brief mathematical description supporting our implementations of the Qiskit functions that we will be employing in our classical-quantum classification algorithm.\n",
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"images/qml_workflow_05.png\" />\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "    Figure 0.2. illustrating the full framework for classifying iris species using a QNN. \n",
    "</p>\n",
    "\n",
    "The illustration highlights how current QML pipelines combine classical and quantum information processing methods to perform the classification. Future implementations of QML are expected to include only quantum data and quantum algorithms in the primary pipeline, with classical methods used in the final post-processing stage. For now, the QML pipeline includes a classical-to-quantum conversion step which maps classical data to qubit states using a data encoding scheme, as illustrated in the diagram. \n",
    "\n",
    "The choice of the data encoding scheme contributes to the performance of the model. Although other encoding schemes exist, our focus for this practical will be the Z Feature Map (ZFM) - offering a low circuit depth. We encourage further investigation into other methods, such as Dense Angle Encoding and the Pauli Feature Map. \n",
    "\n",
    "We use the encoded data in a trainable variation quantum circuit (which is sometimes referred to as an \"ansatz\"). At the core of the QNN algorithm, the variational circuit is used iteratively to generate the kernel matrix of the data in a higher dimensional space. Producing a single kernel matrix element requires the inner product of the two quantum values encoded by the ZFM. When the kernel matrix entries have been calculated, we apply a classical machine learning framework to our testing data to obtain an accuracy score.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ad7d8",
   "metadata": {},
   "source": [
    "### 1. Loading the Classical Iris Data to A Quantum Circuit <a id=\"cml\"></a>\n",
    "For compatibility with the quantum part of the QML algorithm, classical data is loaded and preprocessed to assume an appropriate form for quantum encoding schemes. First, we load the the Iris dataset from the $\\texttt{sklearn.dataset}$ module. We then explore the data using visualization techniques to construct an intuitive picture of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a982755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the Iris data set from the sklearn module\n",
    "iris_dataset = datasets.load_iris()\n",
    "\n",
    "# Print dataset description\n",
    "print(iris_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf2741",
   "metadata": {},
   "source": [
    "We can highlight a few interesting observations from this dataset description:\n",
    "\n",
    "- There are 150 samples (instances) in the dataset.\n",
    "- There are four features (attributes) in each sample.\n",
    "- There are three labels (classes) in the dataset.\n",
    "- The dataset is perfectly balanced, as there are the same number of samples (50) in each class.\n",
    "- We can see features are not normalized, and their value ranges are different, e.g., $[4.3, 7.9]$ and $[0.1, 2.5]$ for sepal length and petal width, respectively. So, transforming the features to the same scale may be helpful.\n",
    "- As stated in the table above, feature-to-class correlation in some cases is very high; this may lead us to think that our model should cope well with the dataset.\n",
    "\n",
    "We only examined the dataset description, but additional properties are available in the `iris_data` object. Now we are going to work with features and labels from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79244a3d",
   "metadata": {},
   "source": [
    "##### A. Data Analysis and Feature Extraction <a id=\"data_analysis\"></a>\n",
    "\n",
    "For this demonstration, we define the classical $\\texttt{iris\\_dataset}$ as a set $X$ consisting of $M=4$ data vectors corresponding to each feature, given by, $\\begin{align} X & = \\{\\vec{x}^{(j)} |j \\in [M]\\} \\nonumber \\end{align}$ where each data vector $\\vec{x}^{(j)} \\in \\mathbb{R}^{N}$. Each data vector has $N = 150$ features representing the sepal length, sepal width, petal length and petal width, respectively.\n",
    "\n",
    "To improve the accuracy of the classical-to-quantum conversion, the set $M$ of features needs to be prepared for mapping to quantum data such that information is not lost and the performance of the model is not compromised. This requires that we formulate a clear understanding of the classical data so that we can curate optimal quantum circuits in the QNN. \n",
    "\n",
    "The code below is used to analyse our data using tables and graphical representations. We also leverage $\\texttt{sklearn}$ functions to extract the features and target names for our model. These features are what we will be encoding to a quantum circuit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "features = iris_dataset.data\n",
    "labels = iris_dataset.target\n",
    "\n",
    "# Instantiate the dataframe \n",
    "df = pd.DataFrame(iris_dataset.data, columns=iris_dataset.feature_names)\n",
    "df[\"class\"] = pd.Series(iris_dataset.target)\n",
    "\n",
    "sns.pairplot(df, hue=\"class\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aadabdb",
   "metadata": {},
   "source": [
    "Plots show that feature values range between 1 and 7 cm. To ensure optimal model performance, we use min-max normalization to rescale the feature vectors of the dataset $X$ before encoding. Min-max normalization takes the ratio of the difference between a datum point $x_{k}^{(i)}$ and the minimum entry in the data vector $\\vec{x}^{(j)}_k$ to the difference between the maximum and minimum entries over the $M$ data vectors in the dataset $X$. Mathematically, we can express min-max normalization as\n",
    "$\\begin{align}x^{'(i)}_{k} & = \\frac{x^{(i)}_k - \\min{\\{x^{(j)}_k|\\vec{x}^{(j)}\\in [X]\\}}}{\\max{\\{x^{(j)}_k|\\vec{x}^{(j)}\\in [X]\\}} - \\min{\\{x^{(j)}_k|\\vec{x}^{(j)}\\in [X]}\\}}\\nonumber\\end{align}$\n",
    "which produces values that fall between 0 and 1. When encoding data to quantum phase information, as in the case of our ZFM implementation, we rescale feature vectors as $\\vec{x}_{i}^{(j)}\\in (0, 2\\pi]$. The code in the cell normalizes the feature vectors for the sepal length and width, as well as the petal length and width. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = MinMaxScaler().fit_transform(features)\n",
    "df_normalized = pd.DataFrame(features, columns=iris_dataset.feature_names)\n",
    "df_normalized[\"class\"] = pd.Series(iris_dataset.target)\n",
    "sns.pairplot(df_normalized, hue=\"class\", palette=\"tab10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ab77f",
   "metadata": {},
   "source": [
    "Plots of the normalized data vectors in $X$ confirm that we have successfully rescaled the classical data values to fall within a unit circle. A close look at the plots shows that shape of the data points is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e1f8f",
   "metadata": {},
   "source": [
    "##### B. Splitting Data <a id=\"data_split\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed744f",
   "metadata": {},
   "source": [
    "We can now split our normalized dataset into training and testing sets so that the model can be evaluated with unseen data. The training set is applied to fit the model to the optimal quantum variational circuit, or QNN. After fitting the model to the training set, we can use a validation set for unbiased model evaluation during hyperparameter tuning. In the final step of the Qiskit Pattern, we use the test set for post-processing and exploring techniques for scaling the model and improving model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_globals.random_seed = 123\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features, labels, train_size=0.8, random_state=algorithm_globals.random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e9e55c",
   "metadata": {},
   "source": [
    "As a golden measure, we train a classical Support Vector Classifier (SVC) using the $\\texttt{SVC}$ class from the $\\texttt{sklearn.svm}$ module and evaluate the performance of the model. Typically, we perform the full benchmark at the end of the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "_ = svc.fit(train_features, train_labels)  # suppress printing the return value\n",
    "train_score_c4 = svc.score(train_features, train_labels)\n",
    "test_score_c4 = svc.score(test_features, test_labels)\n",
    "\n",
    "print(f\"Classical SVC on the training dataset: {train_score_c4:.2f}\")\n",
    "print(f\"Classical SVC on the test dataset:     {test_score_c4:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99102dae",
   "metadata": {},
   "source": [
    "The SVC class implements a Support Vector Machine model which is known to perform well on the Iris dataset. Although we compare the results at the end of this pipeline, researchers must be careful to ensure that the problem is suitable for applications of quantum subroutines during assessment of the solution. QML is suitable for more complex datasets which can be represented in Hilbert space without losing information about the structure of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e77192b",
   "metadata": {},
   "source": [
    "##### C. Data Encoding Using the ZFM <a id=\"data_encoding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c0670",
   "metadata": {},
   "source": [
    "A data encoding scheme is analogous to an analog-to-digital (ADC) or digital-to-analog (DAC) in that it converts signal (or information) from one domain to another. We implement this 'quantum ADC' in converting datapoints that were sampled classically to Hilbert spaces of a quantum computer. There are many such data encoding schemes that can be used to map our classical dataset for quantum processing unit (QPU) execution. The fundamental encoding schemes used in constructing more complex mappings include:\n",
    "* Basis Encoding\n",
    "* Amplitude Encoding\n",
    "* Angle Encoding\n",
    "* Phase Encoding\n",
    "\n",
    "For example, dense angle encoding combines angle and phase encoding to facilitate a mapping of two feature values to a single qubit. Similarly, the ZFM extends concepts of phase encoding to include alternating layers of Hadamard and phase gate layers. Given a data vector $\\vec{x}$ with $N$ features, the quantum circuit that performs the feature mapping is represented as a unitary operator $U(\\vec{x})$ that acts on the initial qubit ground state $\\ket{0}^{\\otimes N}$, i.e.,\n",
    "$\\begin{align}U(\\vec{x})\\ket{0}^{\\otimes N} & = \\ket{\\phi(\\vec{x})}\\nonumber\\end{align}$\n",
    "where $\\ket{\\phi(\\vec{x})}$ is the mapping $\\phi$ of data vector $\\vec{x}$ consisting of alternating layers of single-qubit gates.\n",
    "\n",
    "In the Hadamard layer of the encoding circuit, each qubit in the register is acted on by an $H$ gate. Likewise, the $i^{\\text{th}}$ qubit is acted on by a $P$ gate with one feature as an argument.\n",
    "\n",
    "This implies that we can express the unitary matrix $U(\\vec{x})$ of our ZFM for the Iris dataset as,\n",
    "$\\begin{align}U_{ZFM}(\\vec{x}) & = \\left(\\bigotimes_{k=1}^{N}P(\\vec{x}_k)\\right)H^{\\otimes N}= [P(\\vec{x}_1)\\otimes P (\\vec{x}_2)\\otimes P(\\vec{x}_3)\\otimes P(\\vec{x}_4)]H^{\\otimes 4}\\nonumber\\end{align}$ \n",
    "The resulting quantum circuit is applied iteratively for $r$ repetitions to generate a final product state. The code below applies the built-in ZFM Qiskit class which takes in the same number of qubits as the number entries in each feature vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the features using an Ansatz\n",
    "num_features = features.shape[1]\n",
    "feature_map = ZFeatureMap(feature_dimension=num_features)\n",
    "\n",
    "# Visualize the circuit\n",
    "feature_map.decompose().draw(output='mpl', fold=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adffb39",
   "metadata": {},
   "source": [
    "In the above quantum circuit illustrating the full ZFM for 3 repetitions of Hadamard and phase gates, each Iris feature $x_i$, in data vector $\\vec{x}_1$,  is mapped to one quantum state. By expressing the initial state $\\ket{\\psi}$ of the quantum system as \n",
    "$\\begin{align} \\ket{\\psi} & = \\ket{0000}\\nonumber \\end{align}$\n",
    "we can apply the ZFM circuit unitary operator to obtain,\n",
    "$\\begin{align} U(\\vec{x})\\ket{0000} & = P(\\vec{x})^{\\otimes 4}H^{\\otimes 4}\\ket{0000}\\\\ & = (P(x_1)H\\ket{0})\\otimes (P(x_2)H\\ket{0})\\otimes (P(x_3)H\\ket{0})\\otimes (P(x_4)H\\ket{0})\\nonumber\\end{align}$\n",
    "Therefore, we see that a Hadamard gate and phase gate are applied to each qubit in the register. Recall that the Hadamard gate constructively decomposes the $\\ket{0}$ state into a linear combination of states. The phase gate changes the relative phase of the quantum states without affecting the complex amplitude of their wave functions. In other words, the phase gate rotates a qubit around the $z$-axis by an angle proportional to the normalized feature $x_i$.\n",
    "\n",
    "The process of decomposing the wave function and introducing a phase shift using Hadamard and phase gates is repeated multiple times to procude the kernel matrix. This process generates a kernel matrix corresponding to the probability of measuring the ground state. This circuit is known as an *ansatz* circuit, from the German word referring to nascent steps or a way of tackling a task or problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa95d7e",
   "metadata": {},
   "source": [
    "#### 2. Generating and Adjusting the QNN <a id=\"data_encoding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01632faf",
   "metadata": {},
   "source": [
    "If we continue with our juxtaposition of quantum circuits to electronic circuits, then we can say that a VQC is a quantum circuit that behaves like an $k-th$ order filter, where $k$ is equivalent to the number of layers, or circuit depth, of the ansatz. We can compare this to the effect that the order of a filter has on the rate at which the amplitude of a signal is attenuated. \n",
    "\n",
    "Similar to the design of a filter, careful considerations have to be made when constructing a training ansatz. The considerations include:\n",
    "\n",
    "* Circuit depth: to prevent excessive hardware errors, we must ensure that we do not perform more operations than possible. \n",
    "* Parametrized circuit: we must decide on whether parameters of single or entangling gates should be varied.\n",
    "* Number of Parameters: we must choose the number of parameters such that the overhead of impelementing parametrized quantum gates is reduced.\n",
    "\n",
    "The code applies the above considerations to generate the full ansatz which introduces entangled gates to the QML pipeline. The entangled qubits create a structure that is analogous to a neural network as illustrated in figure 2.1. below. We choose to parameterise the ansatz circuit by $\\theta$ and couple the qubits using a $\\texttt{CNOT}$ gate which entangles them.\n",
    "\n",
    "<p>\n",
    "    <img src=\"images/qnn_vqc_illustration.png\" />\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "    Figure 2.1. Full QNN quantum circuit for the combine ZFM and ansatz.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d350ca-a6b5-432e-b019-1a7464bf21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = num_features\n",
    "\n",
    "# Using RealAmplitudes Ansatz for encoding\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
    " \n",
    "# Draw the circuit\n",
    "ansatz.decompose().draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12a7ce-1428-4966-a4a9-f2e32d0da946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the ZFM with Ansatz\n",
    "# cr = ClassicalRegister(1, name=\"cr\")\n",
    "qnn_vqc = QuantumCircuit(QuantumRegister(num_qubits))\n",
    "qnn_vqc.compose(feature_map, range(num_qubits), inplace=True)\n",
    "qnn_vqc.compose(ansatz, range(num_qubits), inplace=True)\n",
    " \n",
    "# Display the circuit\n",
    "qnn_vqc.decompose().draw(\"mpl\", style=\"clifford\", fold=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2832c26",
   "metadata": {},
   "source": [
    "In the first layer of the QNN ansatz circuit, we rotate each qubit around the $y$-axis by the parameter $\\theta$. This is to say that we parametrise the single-qubit R<sub>Y</sub> gate in the ansatz, corresponding to the unitary matrix operation given by\n",
    "$\\begin{align}R_Y & = \\left(\\begin{matrix} \\cos(\\frac{\\theta}{2}) & -\\sin(\\frac{\\theta}{2}) \\\\ \\sin(\\frac{\\theta}{2}) & \\cos(\\frac{\\theta}{2})\\end{matrix}\\right)\\nonumber\\end{align}$\n",
    "Note that when $\\theta = \\pi$, we are effectively applying a Y gate which affects the qubit state and introduces a phase shift of $180\\degree$. \n",
    "\n",
    "The second layer, we entangle logically adjacent qubits using the $\\texttt{CNOT}$ gate. Recall that we can represent the results of a $\\texttt{CNOT}$ gate using a Truth Table as shown in table 2.1. below.\n",
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"images/cnot_truth_table.png\" />\n",
    "</p>\n",
    "<p style=\"text-align:center;\">\n",
    "    Table 2.1. Truth table for CNOT gate showing the control, target and resultant qubit states.\n",
    "</p>\n",
    "\n",
    "In the final layer, we apply a R<sub>X</sub> to rotate each qubit around the $x$-axis of the Bloch sphere by angle $\\theta$. This results in a superposition of states for each qubit. From the definition of the R<sub>X</sub> gate expressed as the unitary matrix operator given by,\n",
    "$\\begin{align}R_Y & = \\left(\\begin{matrix} \\cos(\\frac{\\theta}{2}) & -i\\sin(\\frac{\\theta}{2}) \\\\ -i\\sin(\\frac{\\theta}{2}) & \\cos(\\frac{\\theta}{2})\\end{matrix}\\right)\\nonumber\\end{align}$\n",
    "we can deduce that when $\\theta = \\pi$, we are flipping the state of the qubit from $\\ket{0}$ to $\\ket{1}$ or vice versa.\n",
    "\n",
    "To interpret the results of the full circuit classically, we require an observable that produces an expectation value. The Qiskit SDK offers the Estimator which can be used to amalgamate quantum states such that we can perform measurements on a subset of the quantum kernel space produced by the QNN. Alternatively, we can use the $\\texttt{EstimatorV2}$ to measure some attribute from each qubit by applying an I, X, Y or Z operator to each qubit. In this case, we will estimate the expectation value by computing the number of counts and dividing them by the number of executed shots. This is performed in the code below where where we use a function to run a foward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the QNN function for later\n",
    "def forward_qnn(\n",
    "    qnn_qc: QuantumCircuit,\n",
    "    theta_params: np.ndarray,\n",
    "    weight_params: np.ndarray,\n",
    "    estimator: BaseEstimatorV2,\n",
    "    observable: BaseOperator,\n",
    ") -> np.ndarray:\n",
    "    \n",
    "    num_samples = theta_params.shape[0]\n",
    "    weights = np.broadcast_to(weight_params, (num_samples, len(weight_params)))\n",
    "    params = np.concatenate((theta_params, weights), axis=1)\n",
    "    pub = (qnn_qc, observable, params)\n",
    "    job = estimator.run([pub])\n",
    "    result = job.result()[0]\n",
    "    expectation_values = result.data.evs\n",
    " \n",
    "    return expectation_values\n",
    "\n",
    "\n",
    "# Define the Z operator observable which produces -1, 0, 1\n",
    "observable = SparsePauliOp.from_list([(\"ZX\" * (int(num_qubits/2)), 1)])\n",
    "np.random.seed(42)\n",
    "weight_params = np.random.rand(len(ansatz.parameters)) * 2 * np.pi\n",
    "qnn_vqc.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7542c",
   "metadata": {},
   "source": [
    "We apply gradient-based loss function which takes in the labels predicted by our VQC and the correct labels before returning the mean squared errror (MSE). We also apply a function that takes in the VQC parameters as inputs for use by the COBYLA classical optimiser which trains the model by sampling the dynamic weights to decrease the MSE. The result from these functions are used to indicate the accuracy of our QNN. Note that classical deep learning frameworks use a similar technique to in gradient-based techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "vqc = qnn_vqc\n",
    "observables = observable\n",
    "input_params = train_features\n",
    "target = train_labels\n",
    "estimator = Estimator()\n",
    "gradient = []\n",
    "iter = 0\n",
    "\n",
    "def loss(predict: np.ndarray, target: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "     Loss function for calculating the MSE.\n",
    "    \"\"\"\n",
    "    if len(predict.shape) <= 1:\n",
    "        return ((predict - target) ** 2).mean()\n",
    "    else:\n",
    "        raise AssertionError(\"input should be 1d-array\")\n",
    "\n",
    "def loss_weights(weight_params: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Cost function for use by classical optimiser.\n",
    "    \"\"\"\n",
    "    predictions = forward_qnn(\n",
    "        qnn_qc=vqc,\n",
    "        theta_params=input_params,\n",
    "        weight_params=weight_params,\n",
    "        estimator=estimator,\n",
    "        observable=observables,\n",
    "    )\n",
    " \n",
    "    cost = loss(predict=predictions, target=target)\n",
    "    objective_func_vals.append(cost)\n",
    "    gradient.append(cost)\n",
    " \n",
    "    global iter\n",
    "    if iter % 50 == 0:\n",
    "        print(f\"Iter: {iter}, loss: {cost}\")\n",
    "    iter += 1\n",
    " \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a41075",
   "metadata": {},
   "source": [
    "### 3. Optimising the Problem for Quantum Execution <a id=\"optimise\"></a>\n",
    "\n",
    "IBM Quantum systems have different properties such as single and two-qubit gate error rates, read-out rates and qubit coupling maps. In this step of our pipeline, we select the least-busy quantum system for execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1686c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a real backend whith low waiting times\n",
    "backend = service.least_busy(operational=True, simulator=False)\n",
    "print(backend.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b06bc03",
   "metadata": {},
   "source": [
    "The Qiskit SDK allows us to optimise a logical quantum circuit for QPU execution using a preset pass manager based on the layout of physical qubits on the available quantum system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b887ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = backend.target\n",
    "# Construct standalone PassManager for handling task scheduling\n",
    "pass_manager = generate_preset_pass_manager(target=target, optimization_level=3)\n",
    "pass_manager.scheduling = PassManager(\n",
    "    [\n",
    "        # ALAP Schedule Pass class created with target backend\n",
    "        ALAPScheduleAnalysis(target=target),\n",
    "        # Rescheduler class for handling time resolution\n",
    "        ConstrainedReschedule(\n",
    "            acquire_alignment=target.acquire_alignment,\n",
    "            pulse_alignment=target.pulse_alignment,\n",
    "            target=target,\n",
    "        ),\n",
    "        # Pass class for dynamic decoupling in idle periods\n",
    "        PadDynamicalDecoupling(\n",
    "            target=target,\n",
    "            dd_sequence=[XGate(), XGate()],\n",
    "            pulse_alignment=target.pulse_alignment,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# Execute the defined schedule of passes to transpile your circuit for the device\n",
    "physical_qubits = pass_manager.run(qnn_vqc)\n",
    "# Mapp the obervable to the physical layout of the used device\n",
    "physical_observable = observable.apply_layout(physical_qubits.layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae0092",
   "metadata": {},
   "source": [
    "### 4. Executing Qiskit Primitives <a id=\"execute\"></a>\n",
    "\n",
    "We can now execute the optimized circuit on the QPU using Qiskit Primitives. We begin by debugging the circuit using a simulator to loop over the dataset for $b$ batches and $m$ epochs to train our QNN. Notice how decreasing the batch number affects the accuracy of the QNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edf8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "num_epochs = 5\n",
    "num_samples = len(train_features)\n",
    "objective_func_vals = []\n",
    "\n",
    "# Random initial weights for the ansatz. The fixed seed allows to replicate the experiment.\n",
    "# This was already set above, but you can try to change the seed to see the difference.\n",
    "# np.random.seed(42)\n",
    "# weight_params = np.random.rand(len(ansatz.parameters)) * 2 * np.pi\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range((num_samples - 1) // batch_size + 1):\n",
    "        print(f\"Epoch: {epoch}, batch: {i}\")\n",
    "        start_i = i * batch_size\n",
    "        end_i = start_i + batch_size\n",
    "        train_iris_batch = np.array(train_features[start_i:end_i])\n",
    "        train_labels_batch = np.array(train_labels[start_i:end_i])\n",
    "        input_params = train_iris_batch\n",
    "        target = train_labels_batch\n",
    "        iter = 0\n",
    "        res = minimize(\n",
    "            loss_weights, weight_params, method=\"COBYLA\", options={\"maxiter\": 100}\n",
    "        )\n",
    "        weight_params = res[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3e5f3",
   "metadata": {},
   "source": [
    "### 5. Post-Processing Results to Extract Classical Data <a id=\"post\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f433f1",
   "metadata": {},
   "source": [
    "In the final step of our adaptation of the Qiskit Pattern, we determine the training accuracy to interpret the above results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = forward_qnn(vqc, np.array(train_features), res[\"x\"], estimator, observable)\n",
    "# pred_train = forward(circuit_ibm, np.array(train_images), res['x'], estimator, observable_ibm)\n",
    " \n",
    "print(pred_train)\n",
    "# Define the ternary thresholds\n",
    "threshold_low = 0.25\n",
    "threshold_high = 0.3\n",
    "\n",
    "# Apply the thresholds to the predictions\n",
    "pred_train_labels = copy.deepcopy(pred_train)\n",
    "index = 0\n",
    "for pred in pred_train:\n",
    "    if pred < threshold_low:\n",
    "        pred_train_labels[index] = 0\n",
    "    elif pred >= threshold_low and pred < threshold_high: \n",
    "        pred_train_labels[index] = 2\n",
    "    else:\n",
    "        pred_train_labels[index] = 1\n",
    "    index+=1\n",
    "\n",
    "print(pred_train_labels)\n",
    "print(train_labels)\n",
    " \n",
    "accuracy = accuracy_score(train_labels, pred_train_labels)\n",
    "print(f\"Train accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = forward_qnn(vqc, np.array(test_features), res[\"x\"], estimator, observable)\n",
    "# pred_test = forward(circuit_ibm, np.array(test_images), res['x'], estimator, observable_ibm)\n",
    " \n",
    "print(pred_test)\n",
    " \n",
    "# Apply the thresholds to the predictions\n",
    "pred_test_labels = copy.deepcopy(pred_test)\n",
    "index = 0\n",
    "for pred in pred_test:\n",
    "    if pred < threshold_low:\n",
    "        pred_test_labels[index] = 0\n",
    "    elif pred >= threshold_low and pred < threshold_high: \n",
    "        pred_test_labels[index] = 2\n",
    "    else:\n",
    "        pred_test_labels[index] = 1\n",
    "    index+=1\n",
    "\n",
    "print(pred_test_labels)\n",
    "print(test_labels)\n",
    " \n",
    "accuracy = accuracy_score(test_labels, pred_test_labels)\n",
    "print(f\"Train accuracy: {accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd016edf",
   "metadata": {},
   "source": [
    "When we use 140 batches, the accuracy of the model exhibits moderate performance, achieving a model training accuracy of 67.5%. This prompts us to investigate potential issues, adjust the ansatz, and optimize our model. To guide our investigation, we can begin by identifying the following plausible causes:\n",
    "* We may have insufficient training iterations, implying that the process may not have been run for enough epochs.\n",
    "* The circuit architecture of the ansatz may not be optimal, leading to poor entanglement and limited classification.\n",
    "\n",
    "This means that to improve the performance of the model, we can increase the number of training epochs to ensure sufficient iterations for the optimizer to find the best parameters. We can also use a different encoding scheme and optimize the ansatz to improve entanglement to avoid overfitting. The code below is used to check for convergence in the optimization which can help us verify whether we constructed an ansatz with poor learnability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_func_vals_first = objective_func_vals\n",
    "# import matplotlib.pyplot as plt\n",
    " \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(obj_func_vals_first, label=\"Iris Dataset Ansatz\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b4d8d",
   "metadata": {},
   "source": [
    "We can check the number of features that were not classified correctly to understand how we can improve the QNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47587ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = []\n",
    "for i in range(len(test_labels)):\n",
    "    if [i] != test_labels[i]:\n",
    "        missed.append(test_labels[i])\n",
    "print(len(missed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db47ad5d",
   "metadata": {},
   "source": [
    "### 6. Conclusion <a id=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cfdf0f",
   "metadata": {},
   "source": [
    "This notebook explored the potential of Quantum Machine Learning for classifying the Iris dataset. While quantum models achieved promising results, they still lag behind their classical counterparts in terms of accuracy and resource efficiency. However, the potential for future advancements in quantum hardware and algorithms suggests that quantum ML will eventually reach parity with classical ML. Quantum models achieved a training accuracy of 67.5% on the Iris dataset using four features, surpassing classical models trained on the same features. Reducing the number of features negatively impacted the performance of both classical and quantum models. In conclusion, the results suggest uantum models require further optimization for better entanglement and learnability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit_summer_school",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
